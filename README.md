# DCGAN for MNIST Data Generation

## Overview
This repository implements a Deep Convolutional Generative Adversarial Network (DCGAN) to generate handwritten digit images similar to those in the MNIST dataset. The project leverages TensorFlow/Keras for model building and training, uses GPU acceleration for speed, and provides comprehensive visualization of results.

## Project Description
The goal is to train a DCGAN that learns the distribution of the MNIST dataset and produces realistic handwritten digits. The implementation consists of two main neural networks:
- **Generator:** Converts a random noise vector into a 28×28 grayscale image.
- **Discriminator:** Distinguishes between real images from the MNIST dataset and images generated by the Generator.

The adversarial training process allows both models to improve over time—ultimately resulting in a generator capable of producing plausible digits.

## Implementation Details
- **Language & Framework:** Python 3.12 with TensorFlow 2.x (using Keras API)
- **GPU Support:** NVIDIA RTX A5000 (CUDA 12.4) used for accelerated training
- **Training Parameters:**
  - **Epochs:** 200
  - **Loss Function:** Binary Cross-Entropy is used for both generator and discriminator losses
  - **Optimizers:** Adam optimizer with customized learning rates and decay schedules
- **Key Files:**
  - `MnistDCGAN.py` – Main training and evaluation script.
  - SLURM batch file (e.g., `model.sbatch`) – For job submission on the HPC cluster.
- **Data:** MNIST dataset is loaded, preprocessed to the [-1, 1] range, and fed into the network.

## Results

| **Final Epoch Grid** | **Training Gif** |
<!-- |:-------:|:---------:|
| ![Final Epoch Grid](./Final-epoch-grid.png) | ![Training Gif](./Training.gif) | 
-->
<table style="width:80%; margin:auto;">
  <tr>
    <th style="text-align:center;">Final Epoch Grid</th>
    <th style="text-align:center;">Training Gif</th>
  </tr>
  <tr>
    <td align="center">
      <img src="./Final-epoch-grid.png" width="300" />
    </td>
    <td align="center">
      <img src="./Rraining.gif" width="300" />
    </td>
  </tr>
</table>



## Loss Function Over 200 Epochs
The loss plot below depicts the training progress, showing the generator and discriminator losses throughout 200 epochs.
  
![Loss Plot](./Loss-plot.png)

## Development Environment
- **Operating Systems:**
  - Local development on macOS
  - HPC cluster (Linux) for large-scale training
- **Python Version:** 3.12
- **TensorFlow Version:** 2.x (tested with TensorFlow 2.9+)
- **CUDA Version:** 12.4 (for GPU acceleration)
- **Additional Tools:**
  - **Jupyter Notebook** for interactive experiment development.
  - **SLURM** for job scheduling on the HPC cluster.
  - **Homebrew** for package management on macOS.

## How to Run
1. **Clone the Repository**
   ```bash
   git clone <repository-url>
   cd <repository-folder>