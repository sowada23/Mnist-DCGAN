# DCGAN for MNIST Data Generation

## Overview
This repository implements a Deep Convolutional Generative Adversarial Network (DCGAN) to generate handwritten digit images similar to those in the MNIST dataset. The project leverages TensorFlow/Keras for model building and training, uses GPU acceleration for speed, and provides comprehensive visualization of results.

## Project Description
The goal is to train a DCGAN that learns the distribution of the MNIST dataset and produces realistic handwritten digits. The implementation consists of two main neural networks:
- **Generator:** Converts a random noise vector into a 28×28 grayscale image.
- **Discriminator:** Distinguishes between real images from the MNIST dataset and images generated by the Generator.

The adversarial training process allows both models to improve over time—ultimately resulting in a generator capable of producing plausible digits.

## Implementation Details
- **Language & Framework:** Python 3.12 with TensorFlow 2.x (using Keras API)
- **GPU Support:** NVIDIA RTX A5000 (CUDA 12.4) used for accelerated training
- **Training Parameters:**
  - **Epochs:** 200
  - **Loss Function:** Binary Cross-Entropy is used for both generator and discriminator losses
  - **Optimizers:** Adam optimizer with customized learning rates and decay schedules
- **Key Files:**
  - `MnistDCGAN.py` – Main training and evaluation script.
  - SLURM batch file (e.g., `model.sbatch`) – For job submission on the HPC cluster.
- **Data:** MNIST dataset is loaded, preprocessed to the [-1, 1] range, and fed into the network.

## Results

### Generate using fixed noise (fixed_z_)
| **GAN** | **DCGAN** |
|:-------:|:---------:|
| ![GAN Epoch 59](./images/gan_epoch59.png) | ![DCGAN Epoch 19](./images/dcgan_epoch19.png) |
| *Epoch 59* | *Epoch 19* |

---

### Final Epoch Image
Below is the generator output at the final epoch (e.g., epoch 200):

![Final Epoch Image](./images/final_epoch.png)

---

### Training Progression GIF
Here’s an animation showing how the generated samples evolve over training:

![Training GIF](./images/training.gif)

### Loss Function Over 200 Epochs
The loss plot below depicts the training progress, showing the generator and discriminator losses throughout 200 epochs.
  
![Loss Plot](./loss_plot_20250409_171730%20(2).png)

## Development Environment
- **Operating Systems:**
  - Local development on macOS
  - HPC cluster (Linux) for large-scale training
- **Python Version:** 3.12
- **TensorFlow Version:** 2.x (tested with TensorFlow 2.9+)
- **CUDA Version:** 12.4 (for GPU acceleration)
- **Additional Tools:**
  - **Jupyter Notebook** for interactive experiment development.
  - **SLURM** for job scheduling on the HPC cluster.
  - **Homebrew** for package management on macOS.

## How to Run
1. **Clone the Repository**
   ```bash
   git clone <repository-url>
   cd <repository-folder>